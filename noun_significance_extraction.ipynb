{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\thrdl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "import os\n",
    "from itertools import chain\n",
    "import ast\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    sentences = df.text.to_list()\n",
    "    \n",
    "    flat_list = []\n",
    "    for sublist in sentences:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(words):\n",
    "    nouns = []\n",
    "    porter = PorterStemmer()\n",
    "    for word, tag in words:\n",
    "        if tag.startswith('NN'):\n",
    "            if p.singular_noun(word):\n",
    "                nouns.append(p.singular_noun(word)) #plural nouns to singular nouns\n",
    "            else:\n",
    "                nouns.append(word)\n",
    "            #nouns.append(porter.stem(word)) #convert words to their basic form\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(words):\n",
    "    dict_of_words = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in dict_of_words:\n",
    "            dict_of_words[word] += 1\n",
    "        else:\n",
    "            dict_of_words[word] = 1\n",
    "    return dict_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_used_noun_frequency(dic_1, dic_2, threshold_significance = 10):\n",
    "    significant_nouns = {}\n",
    "    for key, val in dic_1.items():\n",
    "        significant_nouns[key] = [val, 0]\n",
    "    \n",
    "    for key, val in dic_2.items():\n",
    "        if key in significant_nouns:\n",
    "            significant_nouns[key] = [significant_nouns[key][0], val]\n",
    "        else:\n",
    "            significant_nouns[key] = [0, val]\n",
    "            \n",
    "    for key, val in significant_nouns.copy().items():\n",
    "        if (val[0] <= threshold_significance) and (val[1] <= threshold_significance):\n",
    "            del significant_nouns[key]\n",
    "        \n",
    "    print(f\"number of significant nouns: {len(significant_nouns.keys())}\")\n",
    "    return significant_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imbalanced_nouns(dic, n1_coef, n2_coef, coef = 2.5):\n",
    "    nouns_of_interest = []\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if max(n1_coef * val[0], n2_coef * val[1]) - min(n1_coef * val[0], n2_coef * val[1]) * coef > 0:\n",
    "            nouns_of_interest.append(key)\n",
    "    print(f\"number of nouns of interest: {len(nouns_of_interest)}\")\n",
    "    return nouns_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_and_their_synonims(nouns_of_interest, dic_all_nouns, threshold = 0.9):\n",
    "    dic_of_noun_differences = {}\n",
    "    \n",
    "    for noun in nouns_of_interest:\n",
    "\n",
    "            word_meanings = wn.synsets(noun, 'n')\n",
    "            for word_meaning in word_meanings:\n",
    "                for key, val in dic_all_nouns.items():\n",
    "                    if key != noun:\n",
    "\n",
    "                            word_meanings_target = wn.synsets(key, 'n')\n",
    "                            for word_meaning_target in word_meanings_target:\n",
    "                                if word_meaning.wup_similarity(word_meaning_target) > threshold:\n",
    "                                    if noun not in dic_of_noun_differences:\n",
    "                                        dic_of_noun_differences[noun] = set()\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "                                    else:\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "    return dic_of_noun_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_synonyms_set_of_significance(dic_of_noun_differences, dic_noun_frequency, n1_coef, n2_coef):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        #key = word, val = set of synonyms\n",
    "        for noun in val.copy():\n",
    "            if (n1_coef * dic_noun_frequency[key][0] >= n2_coef * dic_noun_frequency[key][1] and n1_coef * dic_noun_frequency[noun][0] >= n2_coef * dic_noun_frequency[noun][1]) or (n1_coef * dic_noun_frequency[key][0] <= n2_coef * dic_noun_frequency[key][1] and n1_coef * dic_noun_frequency[noun][0] <= n2_coef * dic_noun_frequency[noun][1]):\n",
    "                val.remove(noun)\n",
    "    return dic_of_noun_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nouns_stats(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        for noun in val:\n",
    "            print(f\"{key}: {dic_noun_frequency[key][0]} - {dic_noun_frequency[key][1]}, {noun}: {dic_noun_frequency[noun][0]} - {dic_noun_frequency[noun][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'government', 'has', 'no', 'place']\n",
      "['i', 'choose', 'life', 'reagan', 'once']\n",
      "number of significant nouns: 227\n",
      "number of nouns of interest: 38\n",
      "form: 11 - 24, ability: 19 - 13\n",
      "form: 11 - 24, kind: 12 - 10\n",
      "form: 11 - 24, sort: 11 - 3\n",
      "form: 11 - 24, word: 26 - 20\n",
      "form: 11 - 24, state: 58 - 37\n",
      "form: 11 - 24, course: 33 - 18\n",
      "form: 11 - 24, type: 12 - 4\n",
      "organism: 10 - 22, parent: 68 - 45\n",
      "organism: 10 - 22, individual: 30 - 25\n",
      "organism: 10 - 22, animal: 31 - 19\n",
      "type: 12 - 4, form: 11 - 24\n",
      "job: 17 - 5, place: 33 - 34\n",
      "sort: 11 - 3, form: 11 - 24\n",
      "being: 6 - 20, parent: 68 - 45\n",
      "being: 6 - 20, individual: 30 - 25\n",
      "being: 6 - 20, animal: 31 - 19\n",
      "being: 6 - 20, existence: 11 - 8\n",
      "court: 31 - 10, government: 84 - 71\n",
      "rest: 12 - 3, support: 12 - 12\n",
      "rest: 12 - 3, death: 43 - 42\n",
      "beginning: 2 - 14, issue: 63 - 45\n",
      "beginning: 2 - 14, birth: 85 - 57\n",
      "beginning: 2 - 14, part: 35 - 21\n",
      "beginning: 2 - 14, home: 20 - 12\n",
      "beginning: 2 - 14, point: 104 - 72\n",
      "beginning: 2 - 14, constitution: 22 - 10\n",
      "story: 12 - 4, history: 10 - 12\n",
      "story: 12 - 4, life: 366 - 428\n",
      "story: 12 - 4, level: 4 - 14\n",
      "contraceptive: 14 - 2, pill: 12 - 16\n",
      "heart: 9 - 28, feeling: 13 - 8\n",
      "heart: 9 - 28, country: 27 - 20\n",
      "consideration: 11 - 2, thought: 9 - 14\n",
      "science: 5 - 14, ability: 19 - 13\n",
      "level: 4 - 14, point: 104 - 72\n",
      "level: 4 - 14, story: 12 - 4\n",
      "level: 4 - 14, stage: 20 - 13\n",
      "########################################\n",
      "['the', 'emotional', 'argument', 'that', 'gay']\n",
      "['for', 'the', 'record', '-', 'i']\n",
      "number of significant nouns: 258\n",
      "number of nouns of interest: 44\n",
      "body: 7 - 13, organization: 13 - 3\n",
      "body: 7 - 13, form: 30 - 9\n",
      "body: 7 - 13, christianity: 33 - 13\n",
      "black: 19 - 3, man: 189 - 199\n",
      "value: 29 - 5, standard: 13 - 8\n",
      "cause: 12 - 20, case: 45 - 16\n",
      "cause: 12 - 20, origin: 13 - 3\n",
      "notion: 16 - 3, concept: 13 - 13\n",
      "truth: 16 - 27, fact: 123 - 62\n",
      "truth: 16 - 27, statement: 46 - 19\n",
      "bit: 11 - 2, act: 27 - 20\n",
      "wedding: 13 - 2, marriage: 827 - 477\n",
      "wedding: 13 - 2, ceremony: 14 - 9\n",
      "power: 8 - 13, ability: 17 - 6\n",
      "power: 8 - 13, country: 75 - 33\n",
      "power: 8 - 13, hand: 26 - 6\n",
      "thought: 12 - 2, mind: 22 - 16\n",
      "thought: 12 - 2, concept: 13 - 13\n",
      "information: 8 - 13, fact: 123 - 62\n",
      "information: 8 - 13, example: 64 - 21\n",
      "discussion: 13 - 2, word: 46 - 35\n",
      "discussion: 13 - 2, debate: 31 - 25\n",
      "being: 14 - 2, animal: 29 - 17\n",
      "work: 20 - 4, line: 12 - 7\n",
      "work: 20 - 4, action: 12 - 12\n",
      "contact: 12 - 1, line: 12 - 7\n",
      "story: 7 - 11, history: 26 - 11\n",
      "story: 7 - 11, life: 115 - 42\n",
      "story: 7 - 11, level: 17 - 6\n",
      "########################################\n",
      "['it', \"'s\", 'healthier', 'for', 'you']\n",
      "['now', '...', 'i', 'must', 'admit']\n",
      "number of significant nouns: 143\n",
      "number of nouns of interest: 33\n",
      "deal: 11 - 1, pot: 66 - 33\n",
      "product: 20 - 2, issue: 9 - 13\n",
      "product: 20 - 2, effect: 73 - 30\n",
      "product: 20 - 2, job: 15 - 15\n",
      "production: 14 - 1, job: 15 - 15\n",
      "work: 14 - 1, job: 15 - 15\n",
      "case: 19 - 2, problem: 42 - 25\n",
      "case: 19 - 2, cause: 14 - 7\n",
      "case: 19 - 2, example: 11 - 6\n",
      "prohibition: 34 - 4, law: 44 - 26\n",
      "influence: 14 - 13, use: 71 - 19\n",
      "corporation: 14 - 0, pot: 66 - 33\n",
      "marihuana: 13 - 1, marijuana: 344 - 147\n",
      "marihuana: 13 - 1, pot: 66 - 33\n",
      "part: 13 - 1, thing: 71 - 36\n",
      "part: 13 - 1, way: 61 - 31\n",
      "part: 13 - 1, world: 16 - 6\n",
      "one: 26 - 3, i: 187 - 91\n",
      "revenue: 15 - 0, amount: 22 - 12\n",
      "job: 15 - 15, activity: 20 - 4\n",
      "job: 15 - 15, production: 14 - 1\n",
      "job: 15 - 15, product: 20 - 2\n",
      "job: 15 - 15, place: 16 - 3\n",
      "job: 15 - 15, work: 14 - 1\n",
      "issue: 9 - 13, store: 11 - 3\n",
      "issue: 9 - 13, product: 20 - 2\n",
      "issue: 9 - 13, child: 16 - 5\n",
      "issue: 9 - 13, number: 14 - 4\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "for pair in [[\"abortion_pro_choice.csv\", \"abortion_pro_life.csv\"],[\"gay_marriage_for.csv\", \"gay_marriage_against.csv\"],[\"marijuana_legalization_for.csv\",\"marijuana_legalization_against.csv\"]]:\n",
    "    df_1 = pd.read_csv(f\"./dataset_processed/{pair[0]}\", converters={2:ast.literal_eval})\n",
    "    df_2 = pd.read_csv(f\"./dataset_processed/{pair[1]}\", converters={2:ast.literal_eval})\n",
    "    \n",
    "    get_words_1 = get_words(df_1)\n",
    "    get_words_2 = get_words(df_2)\n",
    "    print(get_words_1[0:5])\n",
    "    print(get_words_2[0:5])\n",
    "    \n",
    "    \n",
    "    tags_1 = nltk.pos_tag(get_words_1)\n",
    "    tags_2 = nltk.pos_tag(get_words_2)\n",
    "    \n",
    "    nouns_1 = get_nouns(tags_1)\n",
    "    nouns_2 = get_nouns(tags_2)\n",
    "    \n",
    "    number_of_nouns_1 = len(nouns_1)\n",
    "    number_of_nouns_2 = len(nouns_2)\n",
    "    \n",
    "    n1_coef = 1 - number_of_nouns_1/(number_of_nouns_1 + number_of_nouns_2)\n",
    "    n2_coef = 1 - number_of_nouns_2/(number_of_nouns_1 + number_of_nouns_2)\n",
    "    \n",
    "    frequency_nouns_1 = get_frequency(nouns_1)\n",
    "    frequency_nouns_2 = get_frequency(nouns_2)\n",
    "    \n",
    "    significance_nouns = get_used_noun_frequency(frequency_nouns_1, frequency_nouns_2)\n",
    "    \n",
    "    imbalanced_nouns = get_imbalanced_nouns(significance_nouns, n1_coef, n2_coef)\n",
    "    \n",
    "    dic_of_noun_differences = get_nouns_and_their_synonims(imbalanced_nouns, significance_nouns)\n",
    "    \n",
    "\n",
    "    dic_of_noun_differences = nouns_synonyms_set_of_significance(dic_of_noun_differences, significance_nouns, n1_coef, n2_coef)\n",
    "    \n",
    "    print_nouns_stats(dic_of_noun_differences, significance_nouns)\n",
    "    print(\"########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

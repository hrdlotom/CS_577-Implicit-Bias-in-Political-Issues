{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\thrdl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "import os\n",
    "from itertools import chain\n",
    "import ast\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    sentences = df.text.to_list()\n",
    "    \n",
    "    flat_list = []\n",
    "    for sublist in sentences:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(words):\n",
    "    nouns = []\n",
    "    porter = PorterStemmer()\n",
    "    for word, tag in words:\n",
    "        if tag.startswith('NN'):\n",
    "            if p.singular_noun(word):\n",
    "                nouns.append(p.singular_noun(word)) #plural nouns to singular nouns\n",
    "            else:\n",
    "                nouns.append(word)\n",
    "            #nouns.append(porter.stem(word)) #convert words to their basic form\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(words):\n",
    "    dict_of_words = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in dict_of_words:\n",
    "            dict_of_words[word] += 1\n",
    "        else:\n",
    "            dict_of_words[word] = 1\n",
    "    return dict_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_used_noun_frequency(dic_1, dic_2, threshold_significance = 10):\n",
    "    significant_nouns = {}\n",
    "    for key, val in dic_1.items():\n",
    "        significant_nouns[key] = [val, 0]\n",
    "    \n",
    "    for key, val in dic_2.items():\n",
    "        if key in significant_nouns:\n",
    "            significant_nouns[key] = [significant_nouns[key][0], val]\n",
    "        else:\n",
    "            significant_nouns[key] = [0, val]\n",
    "            \n",
    "    for key, val in significant_nouns.copy().items():\n",
    "        if (val[0] < threshold_significance) and (val[1] < threshold_significance):\n",
    "            del significant_nouns[key]\n",
    "        \n",
    "    print(f\"number of significant nouns: {len(significant_nouns.keys())}\")\n",
    "    return significant_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imbalanced_nouns(dic, coef = 2.2):\n",
    "    nouns_of_interest = []\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if max(val[0], val[1]) - min(val[0], val[1]) * coef > 0:\n",
    "            nouns_of_interest.append(key)\n",
    "    print(f\"number of nouns of interest: {len(nouns_of_interest)}\")\n",
    "    return nouns_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_and_their_synonims(nouns_of_interest, dic_all_nouns, threshold = 0.9):\n",
    "    dic_of_noun_differences = {}\n",
    "    \n",
    "    for noun in nouns_of_interest:\n",
    "\n",
    "            word_meanings = wn.synsets(noun, 'n')\n",
    "            for word_meaning in word_meanings:\n",
    "                for key, val in dic_all_nouns.items():\n",
    "                    if key != noun:\n",
    "\n",
    "                            word_meanings_target = wn.synsets(key, 'n')\n",
    "                            for word_meaning_target in word_meanings_target:\n",
    "                                if word_meaning.wup_similarity(word_meaning_target) > threshold:\n",
    "                                    if noun not in dic_of_noun_differences:\n",
    "                                        dic_of_noun_differences[noun] = set()\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "                                    else:\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "    return dic_of_noun_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_synonyms_set_of_significance(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        #key = word, val = set of synonyms\n",
    "        for noun in val.copy():\n",
    "            if (dic_noun_frequency[key][0] >= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] >= dic_noun_frequency[noun][1]) or (dic_noun_frequency[key][0] <= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] <= dic_noun_frequency[noun][1]):\n",
    "                val.remove(noun)\n",
    "    return dic_of_noun_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nouns_stats(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        for noun in val:\n",
    "            print(f\"{key}: {dic_noun_frequency[key][0]} - {dic_noun_frequency[key][1]}, {noun}: {dic_noun_frequency[noun][0]} - {dic_noun_frequency[noun][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'government', 'has', 'no', 'place']\n",
      "['i', 'choose', 'life', 'reagan', 'once']\n",
      "number of significant nouns: 254\n",
      "number of nouns of interest: 62\n",
      "attempt: 11 - 4, crime: 14 - 21\n",
      "term: 41 - 18, subject: 7 - 12\n",
      "type: 12 - 4, form: 11 - 24\n",
      "job: 17 - 5, place: 33 - 34\n",
      "sort: 11 - 3, form: 11 - 24\n",
      "being: 6 - 20, living: 24 - 23\n",
      "being: 6 - 20, person: 366 - 335\n",
      "being: 6 - 20, animal: 31 - 19\n",
      "being: 6 - 20, parent: 68 - 45\n",
      "being: 6 - 20, existence: 11 - 8\n",
      "being: 6 - 20, individual: 30 - 25\n",
      "deal: 11 - 4, result: 10 - 12\n",
      "beginning: 2 - 14, birth: 85 - 57\n",
      "beginning: 2 - 14, issue: 63 - 45\n",
      "beginning: 2 - 14, point: 104 - 72\n",
      "beginning: 2 - 14, home: 20 - 12\n",
      "beginning: 2 - 14, constitution: 22 - 10\n",
      "beginning: 2 - 14, part: 35 - 21\n",
      "story: 12 - 4, life: 366 - 428\n",
      "story: 12 - 4, history: 10 - 12\n",
      "story: 12 - 4, level: 4 - 14\n",
      "morality: 14 - 6, conscience: 6 - 10\n",
      "criterion: 5 - 16, control: 40 - 35\n",
      "contraceptive: 14 - 2, pill: 12 - 16\n",
      "heart: 9 - 28, country: 27 - 20\n",
      "heart: 9 - 28, feeling: 13 - 8\n",
      "consideration: 11 - 2, thought: 9 - 14\n",
      "science: 5 - 14, ability: 19 - 13\n",
      "level: 4 - 14, point: 104 - 72\n",
      "level: 4 - 14, story: 12 - 4\n",
      "level: 4 - 14, stage: 20 - 13\n",
      "university: 0 - 11, body: 122 - 105\n",
      "########################################\n",
      "['the', 'emotional', 'argument', 'that', 'gay']\n",
      "['for', 'the', 'record', '-', 'i']\n",
      "number of significant nouns: 283\n",
      "number of nouns of interest: 141\n",
      "country: 75 - 33, power: 8 - 13\n",
      "life: 115 - 42, story: 7 - 11\n",
      "right: 342 - 121, position: 9 - 12\n",
      "equality: 21 - 5, position: 9 - 12\n",
      "example: 64 - 21, information: 8 - 13\n",
      "form: 30 - 9, body: 7 - 13\n",
      "form: 30 - 9, type: 11 - 15\n",
      "black: 19 - 3, man: 189 - 199\n",
      "white: 10 - 3, man: 189 - 199\n",
      "christianity: 33 - 13, body: 7 - 13\n",
      "case: 45 - 16, cause: 12 - 20\n",
      "case: 45 - 16, type: 11 - 15\n",
      "origin: 13 - 3, cause: 12 - 20\n",
      "statement: 46 - 19, truth: 16 - 27\n",
      "place: 40 - 18, position: 9 - 12\n",
      "place: 40 - 18, function: 4 - 10\n",
      "organization: 13 - 3, body: 7 - 13\n",
      "hell: 17 - 4, sin: 37 - 39\n",
      "ability: 17 - 6, power: 8 - 13\n",
      "site: 14 - 6, position: 9 - 12\n",
      "hand: 26 - 6, power: 8 - 13\n",
      "ground: 19 - 5, position: 9 - 12\n",
      "sort: 21 - 6, type: 11 - 15\n",
      "part: 41 - 17, position: 9 - 12\n",
      "part: 41 - 17, function: 4 - 10\n",
      "claim: 29 - 8, use: 9 - 10\n",
      "practice: 17 - 6, use: 9 - 10\n",
      "difference: 26 - 11, distinction: 9 - 10\n",
      "day: 35 - 8, today: 16 - 18\n",
      "level: 17 - 6, story: 7 - 11\n",
      "history: 26 - 11, story: 7 - 11\n",
      "job: 11 - 3, position: 9 - 12\n",
      "abuse: 10 - 3, use: 9 - 10\n",
      "theory: 11 - 3, assumption: 10 - 11\n",
      "view: 36 - 13, orientation: 11 - 12\n",
      "view: 36 - 13, position: 9 - 12\n",
      "preference: 20 - 8, orientation: 11 - 12\n",
      "feeling: 13 - 4, desire: 8 - 11\n",
      "legislation: 4 - 12, government: 83 - 49\n",
      "function: 4 - 10, purpose: 18 - 12\n",
      "function: 4 - 10, ceremony: 14 - 9\n",
      "function: 4 - 10, place: 40 - 18\n",
      "function: 4 - 10, part: 41 - 17\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "for pair in [[\"abortion_pro_choice.csv\", \"abortion_pro_life.csv\"],[\"gay_marriage_for.csv\", \"gay_marriage_against.csv\"]]:\n",
    "    df_1 = pd.read_csv(f\"./dataset_processed/{pair[0]}\", converters={2:ast.literal_eval})\n",
    "    df_2 = pd.read_csv(f\"./dataset_processed/{pair[1]}\", converters={2:ast.literal_eval})\n",
    "    \n",
    "    get_words_1 = get_words(df_1)\n",
    "    get_words_2 = get_words(df_2)\n",
    "    print(get_words_1[0:5])\n",
    "    print(get_words_2[0:5])\n",
    "    \n",
    "    \n",
    "    tags_1 = nltk.pos_tag(get_words_1)\n",
    "    tags_2 = nltk.pos_tag(get_words_2)\n",
    "    \n",
    "    nouns_1 = get_nouns(tags_1)\n",
    "    nouns_2 = get_nouns(tags_2)\n",
    "    \n",
    "    frequency_nouns_1 = get_frequency(nouns_1)\n",
    "    frequency_nouns_2 = get_frequency(nouns_2)\n",
    "    \n",
    "    significance_nouns = get_used_noun_frequency(frequency_nouns_1, frequency_nouns_2)\n",
    "    \n",
    "    imbalanced_nouns = get_imbalanced_nouns(significance_nouns)\n",
    "    \n",
    "    dic_of_noun_differences = get_nouns_and_their_synonims(imbalanced_nouns, significance_nouns)\n",
    "    \n",
    "\n",
    "    dic_of_noun_differences = nouns_synonyms_set_of_significance(dic_of_noun_differences, significance_nouns)\n",
    "    \n",
    "    print_nouns_stats(dic_of_noun_differences, significance_nouns)\n",
    "    print(\"########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\thrdl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "import os\n",
    "from itertools import chain\n",
    "import ast\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    sentences = df.text.to_list()\n",
    "    \n",
    "    flat_list = []\n",
    "    for sublist in sentences:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(words):\n",
    "    nouns = []\n",
    "    porter = PorterStemmer()\n",
    "    for word, tag in words:\n",
    "        if tag.startswith('NN'):\n",
    "            if p.singular_noun(word):\n",
    "                nouns.append(p.singular_noun(word)) #plural nouns to singular nouns\n",
    "            else:\n",
    "                nouns.append(word)\n",
    "            #nouns.append(porter.stem(word)) #convert words to their basic form\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(words):\n",
    "    dict_of_words = {}\n",
    "    \n",
    "    for word in words:\n",
    "        if word in dict_of_words:\n",
    "            dict_of_words[word] += 1\n",
    "        else:\n",
    "            dict_of_words[word] = 1\n",
    "    return dict_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_used_noun_frequency(dic_1, dic_2, threshold_significance = 10):\n",
    "    significant_nouns = {}\n",
    "    for key, val in dic_1.items():\n",
    "        significant_nouns[key] = [val, 0]\n",
    "    \n",
    "    for key, val in dic_2.items():\n",
    "        if key in significant_nouns:\n",
    "            significant_nouns[key] = [significant_nouns[key][0], val]\n",
    "        else:\n",
    "            significant_nouns[key] = [0, val]\n",
    "            \n",
    "    for key, val in significant_nouns.copy().items():\n",
    "        if (val[0] < threshold_significance) and (val[1] < threshold_significance):\n",
    "            del significant_nouns[key]\n",
    "        \n",
    "    print(f\"number of significant nouns: {len(significant_nouns.keys())}\")\n",
    "    return significant_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imbalanced_nouns(dic, coef = 1.8):\n",
    "    nouns_of_interest = []\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if max(val[0], val[1]) - min(val[0], val[1]) * coef > 0:\n",
    "            nouns_of_interest.append(key)\n",
    "    print(f\"number of nouns of interest: {len(nouns_of_interest)}\")\n",
    "    return nouns_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns_and_their_synonims(nouns_of_interest, dic_all_nouns, threshold = 0.92):\n",
    "    dic_of_noun_differences = {}\n",
    "    \n",
    "    for noun in nouns_of_interest:\n",
    "\n",
    "            word_meanings = wn.synsets(noun, 'n')\n",
    "            for word_meaning in word_meanings:\n",
    "                for key, val in dic_all_nouns.items():\n",
    "                    if key != noun:\n",
    "\n",
    "                            word_meanings_target = wn.synsets(key, 'n')\n",
    "                            for word_meaning_target in word_meanings_target:\n",
    "                                if word_meaning.wup_similarity(word_meaning_target) > threshold:\n",
    "                                    if noun not in dic_of_noun_differences:\n",
    "                                        dic_of_noun_differences[noun] = set()\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "                                    else:\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "    return dic_of_noun_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nouns_synonyms_set_of_significance(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        #key = word, val = set of synonyms\n",
    "        for noun in val.copy():\n",
    "            if (dic_noun_frequency[key][0] >= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] >= dic_noun_frequency[noun][1]) or (dic_noun_frequency[key][0] <= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] <= dic_noun_frequency[noun][1]):\n",
    "                val.remove(noun)\n",
    "    return dic_of_noun_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_nouns_stats(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        for noun in val:\n",
    "            print(f\"{key}: {dic_noun_frequency[key][0]} - {dic_noun_frequency[key][1]}, {noun}: {dic_noun_frequency[noun][0]} - {dic_noun_frequency[noun][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'government', 'has', 'no', 'place']\n",
      "['i', 'choose', 'life', 'reagan', 'once']\n",
      "number of significant nouns: 254\n",
      "number of nouns of interest: 83\n",
      "decision: 109 - 56, result: 10 - 12\n",
      "theory: 10 - 5, conception: 36 - 49\n",
      "form: 11 - 24, word: 26 - 20\n",
      "form: 11 - 24, person: 366 - 335\n",
      "form: 11 - 24, sort: 11 - 3\n",
      "form: 11 - 24, state: 58 - 37\n",
      "form: 11 - 24, body: 122 - 105\n",
      "form: 11 - 24, course: 33 - 18\n",
      "form: 11 - 24, type: 12 - 4\n",
      "form: 11 - 24, kind: 12 - 10\n",
      "order: 11 - 6, act: 9 - 11\n",
      "movement: 12 - 6, action: 25 - 31\n",
      "attempt: 11 - 4, crime: 14 - 21\n",
      "constitution: 22 - 10, beginning: 2 - 14\n",
      "course: 33 - 18, form: 11 - 24\n",
      "course: 33 - 18, action: 25 - 31\n",
      "organism: 10 - 22, person: 366 - 335\n",
      "organism: 10 - 22, animal: 31 - 19\n",
      "organism: 10 - 22, parent: 68 - 45\n",
      "organism: 10 - 22, individual: 30 - 25\n",
      "term: 41 - 18, subject: 7 - 12\n",
      "type: 12 - 4, form: 11 - 24\n",
      "job: 17 - 5, place: 33 - 34\n",
      "sort: 11 - 3, form: 11 - 24\n",
      "being: 6 - 20, person: 366 - 335\n",
      "being: 6 - 20, animal: 31 - 19\n",
      "being: 6 - 20, parent: 68 - 45\n",
      "being: 6 - 20, existence: 11 - 8\n",
      "being: 6 - 20, individual: 30 - 25\n",
      "deal: 11 - 4, result: 10 - 12\n",
      "beginning: 2 - 14, issue: 63 - 45\n",
      "beginning: 2 - 14, home: 20 - 12\n",
      "beginning: 2 - 14, constitution: 22 - 10\n",
      "beginning: 2 - 14, part: 35 - 21\n",
      "story: 12 - 4, life: 366 - 428\n",
      "story: 12 - 4, history: 10 - 12\n",
      "story: 12 - 4, level: 4 - 14\n",
      "consequence: 45 - 22, moment: 8 - 14\n",
      "consequence: 45 - 22, matter: 32 - 39\n",
      "consequence: 45 - 22, result: 10 - 12\n",
      "criterion: 5 - 16, control: 40 - 35\n",
      "contraceptive: 14 - 2, pill: 12 - 16\n",
      "heart: 9 - 28, country: 27 - 20\n",
      "consideration: 11 - 2, thought: 9 - 14\n",
      "level: 4 - 14, point: 104 - 72\n",
      "level: 4 - 14, story: 12 - 4\n",
      "level: 4 - 14, stage: 20 - 13\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "for pair in [[\"abortion_pro_choice.csv\", \"abortion_pro_life.csv\"]]:\n",
    "    df_1 = pd.read_csv(f\"./dataset_processed/{pair[0]}\", converters={2:ast.literal_eval})\n",
    "    df_2 = pd.read_csv(f\"./dataset_processed/{pair[1]}\", converters={2:ast.literal_eval})\n",
    "    \n",
    "    get_words_1 = get_words(df_1)\n",
    "    get_words_2 = get_words(df_2)\n",
    "    print(get_words_1[0:5])\n",
    "    print(get_words_2[0:5])\n",
    "    \n",
    "    \n",
    "    tags_1 = nltk.pos_tag(get_words_1)\n",
    "    tags_2 = nltk.pos_tag(get_words_2)\n",
    "    \n",
    "    nouns_1 = get_nouns(tags_1)\n",
    "    nouns_2 = get_nouns(tags_2)\n",
    "    \n",
    "    frequency_nouns_1 = get_frequency(nouns_1)\n",
    "    frequency_nouns_2 = get_frequency(nouns_2)\n",
    "    \n",
    "    significance_nouns = get_used_noun_frequency(frequency_nouns_1, frequency_nouns_2)\n",
    "    \n",
    "    imbalanced_nouns = get_imbalanced_nouns(significance_nouns)\n",
    "    \n",
    "    dic_of_noun_differences = get_nouns_and_their_synonims(imbalanced_nouns, significance_nouns)\n",
    "    \n",
    "\n",
    "    dic_of_noun_differences = nouns_synonyms_set_of_significance(dic_of_noun_differences, significance_nouns)\n",
    "    \n",
    "    print_nouns_stats(dic_of_noun_differences, significance_nouns)\n",
    "    print(\"########################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

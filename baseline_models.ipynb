{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\thrdl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import random\n",
    "import re\n",
    "\n",
    "from collections import Counter, defaultdict \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    sentences = df.text.to_list()    \n",
    "    flat_list = []\n",
    "    for sublist in sentences:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)           \n",
    "    return flat_list\n",
    "\n",
    "def get_nouns(words):\n",
    "    nouns = []\n",
    "    porter = PorterStemmer()\n",
    "    for word, tag in words:\n",
    "            if p.singular_noun(word):\n",
    "                nouns.append(p.singular_noun(word)) #plural nouns to singular nouns\n",
    "            elif tag.startswith('NN'):\n",
    "                nouns.append(word)\n",
    "            #nouns.append(porter.stem(word)) #convert words to their basic form\n",
    "    return nouns\n",
    "\n",
    "def get_noun_pairs(words):\n",
    "    nouns = []\n",
    "    noun_pairs = []\n",
    "    porter = PorterStemmer()\n",
    "    for i, (word, tag) in enumerate(words):\n",
    "        if i > 0 and tag.startswith('NN') and (words[i-1][1].startswith('NN') or words[i-1][1].startswith('JJ') or words[i-1][1].startswith('PRP')):\n",
    "            w1 = p.singular_noun(word) if p.singular_noun(word) else word \n",
    "            w0 = p.singular_noun(words[i-1][0]) if p.singular_noun(words[i-1][0]) else words[i-1][0]\n",
    "            noun_pairs.append(w0+\" \"+w1)\n",
    "        \n",
    "        if p.singular_noun(word):\n",
    "            nouns.append(p.singular_noun(word)) #plural nouns to singular nouns\n",
    "        elif tag.startswith('NN'):\n",
    "            nouns.append(word)\n",
    "            #nouns.append(porter.stem(word)) #convert words to their basic form\n",
    "    return nouns, noun_pairs\n",
    "\n",
    "def bow(sentence, corpus, pairs):\n",
    "    bag_vector = np.zeros(len(corpus)+len(pairs))\n",
    "    for w in sentence:     \n",
    "        if p.singular_noun(w):\n",
    "            w = p.singular_noun(w)\n",
    "        for i,word in enumerate(corpus):\n",
    "            if word == w:\n",
    "                bag_vector[i] += 1\n",
    "    \n",
    "    words_together = \" \".join(sentence)\n",
    "    for i, pair in enumerate(pairs):\n",
    "        ctn = len(re.findall(pair, words_together))\n",
    "        bag_vector[len(corpus)+i] = ctn\n",
    "    \n",
    "    return pd.Series(bag_vector)\n",
    "\n",
    "def bow_sentiment(sentence, corpus, sentiment, pairs):\n",
    "    bag_vector = np.zeros(len(corpus)*3 + len(pairs))\n",
    "    #each sentence (in this case comment) has its own dictionary\n",
    "    for w, sentiment_dic in zip(sentence, sentiment):\n",
    "        #each word in a post that happens to be in corpus is also in sentiment_dic\n",
    "        if p.singular_noun(w):\n",
    "            w = p.singular_noun(w)\n",
    "        if w in sentiment_dic:\n",
    "            #in this case corpus is only needed for indexing - this can be changed by passing a dictionary [word] -> index in bag_vector\n",
    "            i = corpus.index(w)\n",
    "            bag_vector[i*3:i*3+3] = sentiment_dic[w]\n",
    "            \n",
    "    words_together = \" \".join(sentence)\n",
    "    for i, pair in enumerate(pairs):\n",
    "        ctn = len(re.findall(pair, words_together))\n",
    "        bag_vector[len(corpus)*3+i] = ctn\n",
    "    \n",
    "    return pd.Series(bag_vector)\n",
    "\n",
    "def get_used_noun_frequency(dic_1, dic_2, threshold_significance = 10):\n",
    "    significant_nouns = {}\n",
    "    for key, val in dic_1.items():\n",
    "        significant_nouns[key] = [val, 0]\n",
    "    \n",
    "    for key, val in dic_2.items():\n",
    "        if key in significant_nouns:\n",
    "            significant_nouns[key] = [significant_nouns[key][0], val]\n",
    "        else:\n",
    "            significant_nouns[key] = [0, val]\n",
    "            \n",
    "    for key, val in significant_nouns.copy().items():\n",
    "        if (val[0] < threshold_significance) and (val[1] < threshold_significance):\n",
    "            del significant_nouns[key]\n",
    "        \n",
    "    print(f\"number of significant nouns: {len(significant_nouns.keys())}\")\n",
    "    return significant_nouns\n",
    "\n",
    "def get_imbalanced_nouns(dic, coef = 2.2):\n",
    "    nouns_of_interest = []\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if max(val[0], val[1]) - min(val[0], val[1]) * coef > 0:\n",
    "            nouns_of_interest.append(key)\n",
    "    print(f\"number of nouns of interest: {len(nouns_of_interest)}\")\n",
    "    return nouns_of_interest\n",
    "\n",
    "def get_nouns_and_their_synonims(nouns_of_interest, dic_all_nouns, threshold = 0.9):\n",
    "    dic_of_noun_differences = {}\n",
    "    \n",
    "    for noun in nouns_of_interest:\n",
    "            word_meanings = wn.synsets(noun, 'n')\n",
    "            for word_meaning in word_meanings:\n",
    "                for key, val in dic_all_nouns.items():\n",
    "                    if key != noun:\n",
    "\n",
    "                            word_meanings_target = wn.synsets(key, 'n')\n",
    "                            for word_meaning_target in word_meanings_target:\n",
    "                                if word_meaning.wup_similarity(word_meaning_target) > threshold:\n",
    "                                    if noun not in dic_of_noun_differences:\n",
    "                                        dic_of_noun_differences[noun] = set()\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "                                    else:\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "    return dic_of_noun_differences\n",
    "\n",
    "def nouns_synonyms_set_of_significance(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        #key = word, val = set of synonyms\n",
    "        for noun in val.copy():\n",
    "            if (dic_noun_frequency[key][0] >= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] >= dic_noun_frequency[noun][1]) or (dic_noun_frequency[key][0] <= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] <= dic_noun_frequency[noun][1]):\n",
    "                val.remove(noun)\n",
    "    return dic_of_noun_differences\n",
    "\n",
    "def print_nouns_stats(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        for noun in val:\n",
    "            print(f\"{key}: {dic_noun_frequency[key][0]} - {dic_noun_frequency[key][1]}, {noun}: {dic_noun_frequency[noun][0]} - {dic_noun_frequency[noun][1]}\")\n",
    "            \n",
    "def shuffle_lists_together(a, b):\n",
    "    return shuffle(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(freq_dict, thr):\n",
    "     return {x : freq_dict[x] for x in freq_dict.keys() if freq_dict[x] >= thr}\n",
    "\n",
    "def optimal_threshold(freq_dict, plot=False):\n",
    "    \n",
    "    opt_thr, n_words = 0, len(freq_dict)\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        fig.subplots_adjust(hspace=0.75, wspace=0.5)\n",
    "    \n",
    "    \n",
    "    for ix, thr in enumerate(range(2, 11)):\n",
    "        fil_frequency = filter_dict(freq_dict, thr)\n",
    "        \n",
    "        if (n_words - len(fil_frequency)) >= 50:\n",
    "            n_words = len(fil_frequency)\n",
    "            opt_thr = thr \n",
    "        else:\n",
    "            n_words = len(fil_frequency)\n",
    "        \n",
    "        if plot:\n",
    "            x = np.arange(len(fil_frequency))\n",
    "            y = np.array(list(fil_frequency.values()))  \n",
    "            ax = fig.add_subplot(5, 2, ix+1)\n",
    "            ax.plot(x, y)\n",
    "            ax.set_title('Threshold = '+ str(thr))\n",
    "            ax.set_ylabel('frequency')\n",
    "            ax.set_xlabel('# of words')\n",
    "    \n",
    "    if plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return opt_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(X_train, y_train):\n",
    "    pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "\n",
    "    param_grid = [\n",
    "        {'classifier' : [LogisticRegression()],\n",
    "         'classifier__penalty' : ['l1', 'l2'],\n",
    "        'classifier__C' : np.logspace(-4, 4, 20),\n",
    "        'classifier__solver' : ['liblinear']}\n",
    "    ]\n",
    "\n",
    "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs=-1)\n",
    "\n",
    "    best_clf = clf.fit(X_train, y_train)\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_similarity(word_meanings_1, word_meanings_2, threshold):\n",
    "    for meaning_1 in word_meanings_1:\n",
    "        for meaning_2 in word_meanings_2:\n",
    "            sim = meaning_1.wup_similarity(meaning_2)\n",
    "            if sim > threshold:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noun_disparity(noun_1, noun_2, freq_dict_1, freq_dict_2, threshold):\n",
    "        \n",
    "    freq_1_1 = freq_dict_1[noun_1]/(freq_dict_1[noun_1] + freq_dict_2[noun_1])\n",
    "    freq_1_2 = freq_dict_2[noun_1]/(freq_dict_1[noun_1] + freq_dict_2[noun_1])\n",
    "    \n",
    "    freq_2_1 = freq_dict_1[noun_2]/(freq_dict_1[noun_2] + freq_dict_2[noun_2])\n",
    "    freq_2_2 = freq_dict_2[noun_2]/(freq_dict_1[noun_2] + freq_dict_2[noun_2])\n",
    "    \n",
    "    if ((freq_1_1 - freq_1_2) > threshold and (freq_2_2 - freq_2_1) > threshold) or ((freq_1_2 - freq_1_1) > threshold and (freq_2_1 - freq_2_2) > threshold):\n",
    "            return True\n",
    "    return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_pairs(freq_dict_1, freq_dict_2):\n",
    "    pairs = []\n",
    "\n",
    "    for noun_1 in freq_dict_1.keys():\n",
    "        word_meanings_1 = wn.synsets(noun_1, 'n')\n",
    "        for noun_2 in freq_dict_2.keys():\n",
    "            if noun_1 != noun_2:\n",
    "                word_meanings_2 = wn.synsets(noun_2, 'n')\n",
    "                # hyperparams in next line (threshold_similarity, noun_disparity)\n",
    "                if threshold_similarity(word_meanings_1, word_meanings_2, 0.75) and noun_disparity(noun_1, noun_2, fil_frequency_nouns_1, fil_frequency_nouns_2, 0.15):\n",
    "                    if (noun_1, noun_2) not in pairs and (noun_2, noun_1) not in pairs:\n",
    "                        pairs.append((noun_1, noun_2))\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y_train):\n",
    "    y_train_one_hot = np.zeros((y_train.shape[0], 1))\n",
    "    for i,y in enumerate(y_train):\n",
    "        if int(y) == 0:\n",
    "            y_train_one_hot[i, 0] = 1        \n",
    "    return y_train_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X_train, y_train_one_hot): \n",
    "   \n",
    "\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, activation='sigmoid', input_shape=input_shape))\n",
    "    model.add(Dense(25, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train, y_train_one_hot, batch_size=100, epochs=70, verbose = 0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def extract_sentiment(sentence, sentiment_threshold = 0.23):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    sentimentValues = [score[\"pos\"], score[\"neg\"], score[\"neu\"]]\n",
    "\n",
    "    if max(score[\"pos\"], score[\"neg\"]) < sentiment_threshold:\n",
    "        return sentimentValues.index(max(sentimentValues))\n",
    "    else:\n",
    "        #only battle between positive and negative sentiment, becase most of the words are just neutral\n",
    "        return sentimentValues.index(max(sentimentValues[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_sentiment_per_post(tr, common):\n",
    "    nouns_sentiments = [] # array of dictionaries\n",
    "    for index, row in tr.iterrows():\n",
    "        nouns_sentiments.append({})\n",
    "        post = \" \".join(row.text)\n",
    "        sentences = re.split('[;.?]', post)\n",
    "        sentences = post.split(',')\n",
    "        for sentence in sentences:\n",
    "            maxSentiment = extract_sentiment(sentence)\n",
    "            for word in sentence.split(' '):\n",
    "                #if word already occured in current post\n",
    "                if p.singular_noun(word):\n",
    "                    word = p.singular_noun(word)\n",
    "                if word in nouns_sentiments[-1]:\n",
    "                    nouns_sentiments[-1][word][maxSentiment] += 1\n",
    "                elif word in common:\n",
    "                    nouns_sentiments[-1][word] = [0, 0, 0]\n",
    "                    nouns_sentiments[-1][word][maxSentiment] += 1\n",
    "    return nouns_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_atributes(t_1, t_2, common, common_3x, sentiment = True, pairs = []):\n",
    "    if sentiment:\n",
    "        sentiment_per_post_1 = get_noun_sentiment_per_post(t_1, common)\n",
    "        sentiment_per_post_2 = get_noun_sentiment_per_post(t_2, common)\n",
    "        t_1['bow_tokens_common'] = t_1.apply(lambda t: bow_sentiment(t.text, common, sentiment_per_post_1, pairs), axis=1).values.tolist()    \n",
    "        t_1[common_3x] = pd.DataFrame(t_1.bow_tokens_common.values.tolist(), index= t_1.index)\n",
    "\n",
    "        t_2['bow_tokens_common'] = t_2.apply(lambda t: bow_sentiment(t.text, common, sentiment_per_post_2, pairs), axis=1).values.tolist()\n",
    "        t_2[common_3x] = pd.DataFrame(t_2.bow_tokens_common.values.tolist(), index= t_2.index)\n",
    "    else:\n",
    "        t_1['bow_tokens_common'] = t_1.apply(lambda t: bow(t.text, common, pairs), axis=1).values.tolist()    \n",
    "        t_1[common_3x] = pd.DataFrame(t_1.bow_tokens_common.values.tolist(), index= t_1.index)\n",
    "\n",
    "        t_2['bow_tokens_common'] = t_2.apply(lambda t: bow(t.text, common, pairs), axis=1).values.tolist()\n",
    "        t_2[common_3x] = pd.DataFrame(t_2.bow_tokens_common.values.tolist(), index= t_2.index)\n",
    "\n",
    "    X_train_1 = np.append(t_1[common_3x], t_2[common_3x], axis = 0)\n",
    "    y_train_1 = np.append(np.zeros(len(t_1)), np.ones(len(t_2)))\n",
    "    X_train_1, y_train_1 = shuffle_lists_together(X_train_1, y_train_1)\n",
    "    \n",
    "    y_train_1_one_hot = one_hot(y_train_1)\n",
    "    return X_train_1, y_train_1, y_train_1_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['birth control', 'pregnant woman', 'their body', 'her choice', 'unwanted child', 'my opinion', 'first place', 'unborn child', 'unwanted pregnancy', 'other person', 'her body', 'human being', 'unborn baby', 'your argument', 'human life']\n",
      "Training Accuracy LR abortion - Common Words + Sentiment: 0.68\n",
      "Training Accuracy NN abortion - Common Words + Sentiment: 0.72\n",
      "Testing Accuracy LR abortion - Common Words + Sentiment: 0.56\n",
      "Testing Accuracy NN abortion - Common Words + Sentiment: 0.54\n",
      "Training Accuracy LR abortion - Common Words: 0.62\n",
      "Training Accuracy NN abortion - Common Words: 0.65\n",
      "Testing Accuracy LR abortion - Common Words: 0.56\n",
      "Testing Accuracy NN abortion - Common Words: 0.59\n"
     ]
    }
   ],
   "source": [
    "topics = { \"abortion\": [\"abortion_pro_choice.csv\", \"abortion_pro_life.csv\"], \n",
    "           \"gay_marriage\":[\"gay_marriage_for.csv\", \"gay_marriage_against.csv\"],\n",
    "           \"darwin_theory_of_evolution\" :[\"darwin_theory_of_evolution_for.csv\", \"darwin_theory_of_evolution_against.csv\"],\n",
    "          \"marijuana_legalization\" :[\"marijuana_legalization_against.csv\", \"marijuana_legalization_for.csv\"],\n",
    "         }\n",
    "\n",
    "for key, pair in topics.items():\n",
    "\n",
    "    df_1 = pd.read_csv(f\"./dataset_processed/{pair[0]}\", converters={2:ast.literal_eval})\n",
    "    df_2 = pd.read_csv(f\"./dataset_processed/{pair[1]}\", converters={2:ast.literal_eval})\n",
    "\n",
    "      \n",
    "    tr_1, ts_1 = train_test_split(df_1, test_size=0.2, random_state=42)\n",
    "    tr_2, ts_2 = train_test_split(df_2, test_size=0.2, random_state=42)\n",
    "    \n",
    "    #X_train, X_val = train_test_split(X_train, test_size=0.25, random_state=34) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    words_1 = get_words(tr_1)\n",
    "    words_2 = get_words(tr_2)\n",
    "\n",
    "    tags_1 = nltk.pos_tag(words_1)\n",
    "    tags_2 = nltk.pos_tag(words_2)\n",
    "\n",
    "\n",
    "    nouns_1, pairs_1 = get_noun_pairs(tags_1)\n",
    "    nouns_2, pairs_2 = get_noun_pairs(tags_2)\n",
    "\n",
    "    frequency_noun_pairs_1 = dict(Counter(pairs_1).most_common())\n",
    "    frequency_noun_pairs_2 = dict(Counter(pairs_2).most_common())\n",
    "    \n",
    "    frequency_nouns_1 = dict(Counter(nouns_1).most_common())\n",
    "    frequency_nouns_2 = dict(Counter(nouns_2).most_common()) \n",
    "    \n",
    "    common_1 = list(frequency_nouns_1.keys())[:22]\n",
    "    common_2 = list(frequency_nouns_2.keys())[:22]\n",
    "    \n",
    "    common_pair_1 = list(frequency_noun_pairs_1.keys())[:10]\n",
    "    common_pair_2 = list(frequency_noun_pairs_2.keys())[:10]\n",
    "\n",
    "    common = list(set([w for w in common_1] + [w for w in common_2]))\n",
    "    common_pair = list(set([w for w in common_pair_1] + [w for w in common_pair_2]))\n",
    "    print(common_pair)\n",
    "\n",
    "    common_3x = list(range(len(common)*3))\n",
    "    common_with_pair = list(range(len(common) + len(common_pair)))\n",
    "    common_3x_with_pair = list(range(len(common)*3 + len(common_pair)))\n",
    "    \n",
    "    #tr_1['bow_tokens_common'] = tr_1.apply(lambda t: bow(t.text, common), axis=1).values.tolist()\n",
    "    #tr_1[common] = pd.DataFrame(tr_1.bow_tokens_common.values.tolist(), index= tr_1.index)\n",
    "\n",
    "    #tr_2['bow_tokens_common'] = tr_2.apply(lambda t: bow(t.text, common), axis=1).values.tolist()\n",
    "    #tr_2[common] = pd.DataFrame(tr_2.bow_tokens_common.values.tolist(), index= tr_2.index)\n",
    "\n",
    "    nouns_sentiments_1 = {}\n",
    "    nouns_sentiments_2 = {}\n",
    "    \n",
    "    X_train_1, y_train_1, y_train_1_one_hot = word_atributes(tr_1, tr_2, common, common_3x_with_pair, True, common_pair)\n",
    "    X_test_1, y_test_1, y_test_1_one_hot = word_atributes(ts_1, ts_2, common, common_3x_with_pair, True, common_pair)\n",
    "    \n",
    "    model_1_1 = lr_model(X_train_1, y_train_1)\n",
    "    model_1_2 = nn_model(X_train_1, y_train_1_one_hot)\n",
    "    \n",
    "    print(f\"Training Accuracy LR {key} - Common Words + Sentiment: {model_1_1.score(X_train_1, y_train_1):.2f}\")\n",
    "    print(f\"Training Accuracy NN {key} - Common Words + Sentiment: {model_1_2.evaluate(X_train_1, y_train_1_one_hot, verbose=0)[1]:.2f}\")    \n",
    "    print(f\"Testing Accuracy LR {key} - Common Words + Sentiment: {model_1_1.score(X_test_1, y_test_1):.2f}\")\n",
    "    print(f\"Testing Accuracy NN {key} - Common Words + Sentiment: {model_1_2.evaluate(X_test_1, y_test_1_one_hot, verbose=0)[1]:.2f}\")\n",
    "             \n",
    "    X_train_1, y_train_1, y_train_1_one_hot = word_atributes(tr_1, tr_2, common, common_with_pair, False, common_pair)\n",
    "    X_test_1, y_test_1, y_test_1_one_hot = word_atributes(ts_1, ts_2, common, common_with_pair, False, common_pair)\n",
    "    \n",
    "    model_1_1 = lr_model(X_train_1, y_train_1)\n",
    "    model_1_2 = nn_model(X_train_1, y_train_1_one_hot)\n",
    "    \n",
    "    print(f\"Training Accuracy LR {key} - Common Words: {model_1_1.score(X_train_1, y_train_1):.2f}\")\n",
    "    print(f\"Training Accuracy NN {key} - Common Words: {model_1_2.evaluate(X_train_1, y_train_1_one_hot, verbose=0)[1]:.2f}\")    \n",
    "    print(f\"Testing Accuracy LR {key} - Common Words: {model_1_1.score(X_test_1, y_test_1):.2f}\")\n",
    "    print(f\"Testing Accuracy NN {key} - Common Words: {model_1_2.evaluate(X_test_1, y_test_1_one_hot, verbose=0)[1]:.2f}\")\n",
    "    \n",
    "    thr_1 = optimal_threshold(frequency_nouns_1)\n",
    "    thr_2 = optimal_threshold(frequency_nouns_2)\n",
    "    thr = max(thr_1, thr_2)\n",
    "\n",
    "    fil_frequency_nouns_1 = filter_dict(frequency_nouns_1, thr)\n",
    "    fil_frequency_nouns_2 = filter_dict(frequency_nouns_2, thr)\n",
    "    \n",
    "    for word in fil_frequency_nouns_1.keys():\n",
    "        if word not in fil_frequency_nouns_2:\n",
    "            fil_frequency_nouns_2[word] = 0\n",
    "        \n",
    "    for word in fil_frequency_nouns_2.keys():\n",
    "        if word not in fil_frequency_nouns_1:\n",
    "            fil_frequency_nouns_1[word] = 0\n",
    "            \n",
    "    pairs = get_similar_pairs(fil_frequency_nouns_1, fil_frequency_nouns_2)\n",
    "    sim_words = list(set([ f1 for f1,f2 in pairs] + [ f2 for f1,f2 in pairs]))\n",
    "    \n",
    "    \n",
    "    sim_3x = list(range(len(sim_words)*3))\n",
    "    sim_3x_pair = list(range(len(sim_words)*3 + len(common_pair)))\n",
    "    sim_words_pair = list(range(len(sim_words) + len(common_pair)))\n",
    "    \n",
    "    X_train_2, y_train_2, y_train_2_one_hot = word_atributes(tr_1, tr_2, sim_words, sim_3x_pair, True, common_pair)\n",
    "    X_test_2, y_test_2, y_test_2_one_hot = word_atributes(ts_1, ts_2, sim_words, sim_3x_pair, True, common_pair)\n",
    "    model_2_1 = lr_model(X_train_2, y_train_2)\n",
    "    model_2_2 = nn_model(X_train_2, y_train_2_one_hot)\n",
    "    \n",
    "    print(f\"Training Accuracy LR {key} - Similar Words + Sentiment: {model_2_1.score(X_train_2, y_train_2):.2f}\")\n",
    "    print(f\"Training Accuracy NN {key} - Similar Words + Sentiment: {model_2_2.evaluate(X_train_2, y_train_2_one_hot, verbose=0)[1]:.2f}\")\n",
    "    print(f\"Testing Accuracy LR {key} - Similar Words + Sentiment: {model_2_1.score(X_test_2, y_test_2):.2f}\")\n",
    "    print(f\"Testing Accuracy NN {key} - Similar Words + Sentiment: {model_2_2.evaluate(X_test_2, y_test_2_one_hot, verbose=0)[1]:.2f}\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    X_train_2, y_train_2, y_train_2_one_hot = word_atributes(tr_1, tr_2, sim_words, sim_words_pair, False, common_pair)\n",
    "    X_test_2, y_test_2, y_test_2_one_hot = word_atributes(ts_1, ts_2, sim_words, sim_words_pair, False, common_pair)\n",
    "    \n",
    "#     print(X_train_2[:3])\n",
    "#     print(y_train_2_one_hot[:3])\n",
    "    model_2_1 = lr_model(X_train_2, y_train_2)\n",
    "    model_2_2 = nn_model(X_train_2, y_train_2_one_hot)\n",
    "    print(f\"Training Accuracy LR {key} - Similar Words: {model_2_1.score(X_train_2, y_train_2):.2f}\")\n",
    "    print(f\"Training Accuracy NN {key} - Similar Words: {model_2_2.evaluate(X_train_2, y_train_2_one_hot, verbose=0)[1]:.2f}\")\n",
    "    print(f\"Testing Accuracy LR {key} - Similar Words: {model_2_1.score(X_test_2, y_test_2):.2f}\")\n",
    "    print(f\"Testing Accuracy NN {key} - Similar Words: {model_2_2.evaluate(X_test_2, y_test_2_one_hot, verbose=0)[1]:.2f}\")\n",
    "    \n",
    "    print(\"----------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22, 10, 0.2, 0.75, 0.15\n",
    "['her body', 'other person', 'unborn baby', 'first place', 'birth control', 'their body', 'your argument', 'pregnant woman', 'unwanted child', 'unborn child', 'human being', 'her choice', 'unwanted pregnancy', 'human life', 'my opinion']\n",
    "Training Accuracy LR abortion - Common Words + Sentiment: 0.67\n",
    "Training Accuracy NN abortion - Common Words + Sentiment: 0.70\n",
    "Testing Accuracy LR abortion - Common Words + Sentiment: 0.56\n",
    "Testing Accuracy NN abortion - Common Words + Sentiment: 0.55\n",
    "Training Accuracy LR abortion - Common Words: 0.62\n",
    "Training Accuracy NN abortion - Common Words: 0.63\n",
    "Testing Accuracy LR abortion - Common Words: 0.58\n",
    "Testing Accuracy NN abortion - Common Words: 0.58\n",
    "Training Accuracy LR abortion - Similar Words + Sentiment: 0.62\n",
    "Training Accuracy NN abortion - Similar Words + Sentiment: 0.63\n",
    "Testing Accuracy LR abortion - Similar Words + Sentiment: 0.53\n",
    "Testing Accuracy NN abortion - Similar Words + Sentiment: 0.54\n",
    "Training Accuracy LR abortion - Similar Words: 0.68\n",
    "Training Accuracy NN abortion - Similar Words: 0.73\n",
    "Testing Accuracy LR abortion - Similar Words: 0.56\n",
    "Testing Accuracy NN abortion - Similar Words: 0.54\n",
    "----------------------------------------\n",
    "['other person', 'civil right', 'your argument', 'civil union', 'gay person', 'gay marriage', 'gay right', 'homosexual couple', 'marriage law', 'gay couple', 'common sense', 'same sex']\n",
    "Training Accuracy LR gay_marriage - Common Words + Sentiment: 0.71\n",
    "Training Accuracy NN gay_marriage - Common Words + Sentiment: 0.69\n",
    "Testing Accuracy LR gay_marriage - Common Words + Sentiment: 0.59\n",
    "Testing Accuracy NN gay_marriage - Common Words + Sentiment: 0.57\n",
    "Training Accuracy LR gay_marriage - Common Words: 0.69\n",
    "Training Accuracy NN gay_marriage - Common Words: 0.70\n",
    "Testing Accuracy LR gay_marriage - Common Words: 0.60\n",
    "Testing Accuracy NN gay_marriage - Common Words: 0.60\n",
    "Training Accuracy LR gay_marriage - Similar Words + Sentiment: 0.66\n",
    "Training Accuracy NN gay_marriage - Similar Words + Sentiment: 0.70\n",
    "Testing Accuracy LR gay_marriage - Similar Words + Sentiment: 0.65\n",
    "Testing Accuracy NN gay_marriage - Similar Words + Sentiment: 0.64\n",
    "Training Accuracy LR gay_marriage - Similar Words: 0.77\n",
    "Training Accuracy NN gay_marriage - Similar Words: 0.77\n",
    "Testing Accuracy LR gay_marriage - Similar Words: 0.66\n",
    "Testing Accuracy NN gay_marriage - Similar Words: 0.67\n",
    "----------------------------------------\n",
    "['scientific theory', 'single cell', 'bang theory', 'intelligent design', 'more cell', 'big bang', 'scientific method', 'micro evolution', 'fossil record', 'other hand', 'evolutionary theory', 'natural selection', 'other word', 'common ancestor', 'sheer coincidence']\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words + Sentiment: 0.66\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words + Sentiment: 0.67\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words + Sentiment: 0.60\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words + Sentiment: 0.58\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words: 0.62\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words: 0.61\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words: 0.61\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words: 0.59\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.61\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.63\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.60\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.59\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.84\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.74\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.47\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.60\n",
    "----------------------------------------\n",
    "['drug dealer', 'brain cell', 'personal relationship', 'your argument', 'your job', 'illegal drug', 'my family', 'marijuana smoke', 'gateway drug', 'dangerou substance', 'many person', 'side effect', 'marijuana use', 'other drug', 'black market', 'drug war']\n",
    "Training Accuracy LR marijuana_legalization - Common Words + Sentiment: 0.79\n",
    "Training Accuracy NN marijuana_legalization - Common Words + Sentiment: 0.72\n",
    "Testing Accuracy LR marijuana_legalization - Common Words + Sentiment: 0.66\n",
    "Testing Accuracy NN marijuana_legalization - Common Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Common Words: 0.70\n",
    "Training Accuracy NN marijuana_legalization - Common Words: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Common Words: 0.67\n",
    "Testing Accuracy NN marijuana_legalization - Common Words: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.70\n",
    "Training Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.69\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.74\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.71\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.68\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.23, 0.75, 0.1\n",
    "Training Accuracy LR abortion - Common Words + Sentiment: 0.66\n",
    "Training Accuracy NN abortion - Common Words + Sentiment: 0.70\n",
    "Testing Accuracy LR abortion - Common Words + Sentiment: 0.56\n",
    "Testing Accuracy NN abortion - Common Words + Sentiment: 0.53\n",
    "Training Accuracy LR abortion - Common Words: 0.60\n",
    "Training Accuracy NN abortion - Common Words: 0.65\n",
    "Testing Accuracy LR abortion - Common Words: 0.57\n",
    "Testing Accuracy NN abortion - Common Words: 0.62\n",
    "Training Accuracy LR abortion - Similar Words + Sentiment: 0.66\n",
    "Training Accuracy NN abortion - Similar Words + Sentiment: 0.65\n",
    "Testing Accuracy LR abortion - Similar Words + Sentiment: 0.52\n",
    "Testing Accuracy NN abortion - Similar Words + Sentiment: 0.53\n",
    "Training Accuracy LR abortion - Similar Words: 0.72\n",
    "Training Accuracy NN abortion - Similar Words: 0.77\n",
    "Testing Accuracy LR abortion - Similar Words: 0.55\n",
    "Testing Accuracy NN abortion - Similar Words: 0.48\n",
    "----------------------------------------\n",
    "Training Accuracy LR gay_marriage - Common Words + Sentiment: 0.71\n",
    "Training Accuracy NN gay_marriage - Common Words + Sentiment: 0.75\n",
    "Testing Accuracy LR gay_marriage - Common Words + Sentiment: 0.63\n",
    "Testing Accuracy NN gay_marriage - Common Words + Sentiment: 0.61\n",
    "Training Accuracy LR gay_marriage - Common Words: 0.66\n",
    "Training Accuracy NN gay_marriage - Common Words: 0.69\n",
    "Testing Accuracy LR gay_marriage - Common Words: 0.65\n",
    "Testing Accuracy NN gay_marriage - Common Words: 0.64\n",
    "Training Accuracy LR gay_marriage - Similar Words + Sentiment: 0.69\n",
    "Training Accuracy NN gay_marriage - Similar Words + Sentiment: 0.75\n",
    "Testing Accuracy LR gay_marriage - Similar Words + Sentiment: 0.64\n",
    "Testing Accuracy NN gay_marriage - Similar Words + Sentiment: 0.60\n",
    "Training Accuracy LR gay_marriage - Similar Words: 0.78\n",
    "Training Accuracy NN gay_marriage - Similar Words: 0.83\n",
    "Testing Accuracy LR gay_marriage - Similar Words: 0.65\n",
    "Testing Accuracy NN gay_marriage - Similar Words: 0.64\n",
    "----------------------------------------\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words + Sentiment: 0.66\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words + Sentiment: 0.70\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words + Sentiment: 0.50\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words + Sentiment: 0.53\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words: 0.62\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words: 0.66\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words: 0.58\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words: 0.58\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.60\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.69\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.60\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.81\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.58\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.50\n",
    "----------------------------------------\n",
    "Training Accuracy LR marijuana_legalization - Common Words + Sentiment: 0.72\n",
    "Training Accuracy NN marijuana_legalization - Common Words + Sentiment: 0.72\n",
    "Testing Accuracy LR marijuana_legalization - Common Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Common Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Common Words: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Common Words: 0.69\n",
    "Testing Accuracy LR marijuana_legalization - Common Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Common Words: 0.68"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.23, 0.75, 0.15\n",
    "Training Accuracy LR abortion - Common Words + Sentiment: 0.66\n",
    "Training Accuracy NN abortion - Common Words + Sentiment: 0.71\n",
    "Testing Accuracy LR abortion - Common Words + Sentiment: 0.56\n",
    "Testing Accuracy NN abortion - Common Words + Sentiment: 0.54\n",
    "Training Accuracy LR abortion - Common Words: 0.60\n",
    "Training Accuracy NN abortion - Common Words: 0.63\n",
    "Testing Accuracy LR abortion - Common Words: 0.57\n",
    "Testing Accuracy NN abortion - Common Words: 0.57\n",
    "Training Accuracy LR abortion - Similar Words + Sentiment: 0.58\n",
    "Training Accuracy NN abortion - Similar Words + Sentiment: 0.63\n",
    "Testing Accuracy LR abortion - Similar Words + Sentiment: 0.58\n",
    "Testing Accuracy NN abortion - Similar Words + Sentiment: 0.55\n",
    "Training Accuracy LR abortion - Similar Words: 0.71\n",
    "Training Accuracy NN abortion - Similar Words: 0.76\n",
    "Testing Accuracy LR abortion - Similar Words: 0.55\n",
    "Testing Accuracy NN abortion - Similar Words: 0.51\n",
    "----------------------------------------\n",
    "Training Accuracy LR gay_marriage - Common Words + Sentiment: 0.71\n",
    "Training Accuracy NN gay_marriage - Common Words + Sentiment: 0.76\n",
    "Testing Accuracy LR gay_marriage - Common Words + Sentiment: 0.61\n",
    "Testing Accuracy NN gay_marriage - Common Words + Sentiment: 0.61\n",
    "Training Accuracy LR gay_marriage - Common Words: 0.68\n",
    "Training Accuracy NN gay_marriage - Common Words: 0.70\n",
    "Testing Accuracy LR gay_marriage - Common Words: 0.64\n",
    "Testing Accuracy NN gay_marriage - Common Words: 0.64\n",
    "Training Accuracy LR gay_marriage - Similar Words + Sentiment: 0.72\n",
    "Training Accuracy NN gay_marriage - Similar Words + Sentiment: 0.73\n",
    "Testing Accuracy LR gay_marriage - Similar Words + Sentiment: 0.62\n",
    "Testing Accuracy NN gay_marriage - Similar Words + Sentiment: 0.60\n",
    "Training Accuracy LR gay_marriage - Similar Words: 0.72\n",
    "Training Accuracy NN gay_marriage - Similar Words: 0.82\n",
    "Testing Accuracy LR gay_marriage - Similar Words: 0.64\n",
    "Testing Accuracy NN gay_marriage - Similar Words: 0.65\n",
    "----------------------------------------\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words + Sentiment: 0.66\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words + Sentiment: 0.70\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words + Sentiment: 0.49\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words + Sentiment: 0.53\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words: 0.62\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words: 0.66\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words: 0.59\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words: 0.56\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.66\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.56\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.74\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.78\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.53\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.47\n",
    "----------------------------------------\n",
    "Training Accuracy LR marijuana_legalization - Common Words + Sentiment: 0.69\n",
    "Training Accuracy NN marijuana_legalization - Common Words + Sentiment: 0.72\n",
    "Testing Accuracy LR marijuana_legalization - Common Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Common Words + Sentiment: 0.67\n",
    "Training Accuracy LR marijuana_legalization - Common Words: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Common Words: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Common Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Common Words: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.72\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.74\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.67\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.67\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.75, 0.05\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.66\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.58\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.79\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.78\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.48\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.51\n",
    "----------------------------------------\n",
    "Training Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.73\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.75\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.69\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.75, 0.1 \n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.61\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.63\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.58\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.59\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.58\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.76\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.58\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.54\n",
    "----------------------------------------\n",
    "Training Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.73\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.75\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.69\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.69\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7, 0.1\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.60\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.64\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.58\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.91\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.74\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.45\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.57\n",
    "----------------------------------------\n",
    "Training Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.79\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.68"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.65, 0.2\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.58\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words + Sentiment: 0.57\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.72\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.73\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.53\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.55\n",
    "----------------------------------------\n",
    "Training Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words + Sentiment: 0.68\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.78\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.67\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.65, 0.1, 20\n",
    "378\n",
    "327\n",
    "Training Accuracy LR abortion - Similar Words: 0.59\n",
    "Training Accuracy NN abortion - Similar Words: 0.63\n",
    "Testing Accuracy LR abortion - Similar Words: 0.54\n",
    "Testing Accuracy NN abortion - Similar Words: 0.51\n",
    "435\n",
    "268\n",
    "Training Accuracy LR gay_marriage - Similar Words: 0.74\n",
    "Training Accuracy NN gay_marriage - Similar Words: 0.75\n",
    "Testing Accuracy LR gay_marriage - Similar Words: 0.61\n",
    "Testing Accuracy NN gay_marriage - Similar Words: 0.62\n",
    "362\n",
    "315\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.67\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.69\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.60\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.57\n",
    "110\n",
    "334\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.68"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.7, 0.05\n",
    "Training Accuracy LR abortion - Similar Words: 0.63\n",
    "Training Accuracy NN abortion - Similar Words: 0.67\n",
    "Testing Accuracy LR abortion - Similar Words: 0.56\n",
    "Testing Accuracy NN abortion - Similar Words: 0.53\n",
    "435\n",
    "268\n",
    "Training Accuracy LR gay_marriage - Similar Words: 0.68\n",
    "Training Accuracy NN gay_marriage - Similar Words: 0.74\n",
    "Testing Accuracy LR gay_marriage - Similar Words: 0.64\n",
    "Testing Accuracy NN gay_marriage - Similar Words: 0.64\n",
    "362\n",
    "315\n",
    "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.69\n",
    "Training Accuracy NN darwin_theory_of_evolution - Similar Words: 0.70\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Similar Words: 0.59\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Similar Words: 0.60\n",
    "196\n",
    "276\n",
    "Training Accuracy LR gun_control - Similar Words: 0.80\n",
    "Training Accuracy NN gun_control - Similar Words: 0.73\n",
    "Testing Accuracy LR gun_control - Similar Words: 0.47\n",
    "Testing Accuracy NN gun_control - Similar Words: 0.52\n",
    "203\n",
    "211\n",
    "Training Accuracy LR climate_change - Similar Words: 0.59\n",
    "Training Accuracy NN climate_change - Similar Words: 0.65\n",
    "Testing Accuracy LR climate_change - Similar Words: 0.47\n",
    "Testing Accuracy NN climate_change - Similar Words: 0.48\n",
    "110\n",
    "334\n",
    "Training Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Training Accuracy NN marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy LR marijuana_legalization - Similar Words: 0.68\n",
    "Testing Accuracy NN marijuana_legalization - Similar Words: 0.68"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "25 size, 0.25 test size, 0.22 nutral thres:\n",
    "Training Accuracy LR abortion - Common Words: 0.64\n",
    "Training Accuracy NN abortion - Common Words: 0.64\n",
    "Testing Accuracy LR abortion - Common Words: 0.58\n",
    "Testing Accuracy NN abortion - Common Words: 0.56\n",
    "Training Accuracy LR gay_marriage - Common Words: 0.68\n",
    "Training Accuracy NN gay_marriage - Common Words: 0.71\n",
    "Testing Accuracy LR gay_marriage - Common Words: 0.66\n",
    "Testing Accuracy NN gay_marriage - Common Words: 0.66\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words: 0.65\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words: 0.68\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words: 0.60\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words: 0.59\n",
    "Training Accuracy LR gun_control - Common Words: 0.68\n",
    "Training Accuracy NN gun_control - Common Words: 0.68\n",
    "Testing Accuracy LR gun_control - Common Words: 0.51\n",
    "Testing Accuracy NN gun_control - Common Words: 0.52\n",
    "Training Accuracy LR climate_change - Common Words: 0.65\n",
    "Training Accuracy NN climate_change - Common Words: 0.65\n",
    "Testing Accuracy LR climate_change - Common Words: 0.51\n",
    "Testing Accuracy NN climate_change - Common Words: 0.48\n",
    "Training Accuracy LR marijuana_legalization - Common Words: 0.76\n",
    "Training Accuracy NN marijuana_legalization - Common Words: 0.70\n",
    "Testing Accuracy LR marijuana_legalization - Common Words: 0.62\n",
    "Testing Accuracy NN marijuana_legalization - Common Words: 0.64"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "25 size, 0.2 test size, 0.23 nutral thres\n",
    "Training Accuracy LR abortion - Common Words: 0.65\n",
    "Training Accuracy NN abortion - Common Words: 0.67\n",
    "Testing Accuracy LR abortion - Common Words: 0.53\n",
    "Testing Accuracy NN abortion - Common Words: 0.54\n",
    "Training Accuracy LR gay_marriage - Common Words: 0.67\n",
    "Training Accuracy NN gay_marriage - Common Words: 0.67\n",
    "Testing Accuracy LR gay_marriage - Common Words: 0.67\n",
    "Testing Accuracy NN gay_marriage - Common Words: 0.67\n",
    "Training Accuracy LR darwin_theory_of_evolution - Common Words: 0.62\n",
    "Training Accuracy NN darwin_theory_of_evolution - Common Words: 0.63\n",
    "Testing Accuracy LR darwin_theory_of_evolution - Common Words: 0.54\n",
    "Testing Accuracy NN darwin_theory_of_evolution - Common Words: 0.58\n",
    "Training Accuracy LR gun_control - Common Words: 0.72\n",
    "Training Accuracy NN gun_control - Common Words: 0.69\n",
    "Testing Accuracy LR gun_control - Common Words: 0.56\n",
    "Testing Accuracy NN gun_control - Common Words: 0.54\n",
    "Training Accuracy LR climate_change - Common Words: 0.66\n",
    "Training Accuracy NN climate_change - Common Words: 0.61\n",
    "Testing Accuracy LR climate_change - Common Words: 0.41\n",
    "Testing Accuracy NN climate_change - Common Words: 0.45\n",
    "Training Accuracy LR marijuana_legalization - Common Words: 0.71\n",
    "Training Accuracy NN marijuana_legalization - Common Words: 0.71\n",
    "Testing Accuracy LR marijuana_legalization - Common Words: 0.62\n",
    "Testing Accuracy NN marijuana_legalization - Common Words: 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

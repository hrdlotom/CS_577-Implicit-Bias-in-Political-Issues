{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from collections import Counter, defaultdict \n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(df):\n",
    "    sentences = df.text.to_list()    \n",
    "    flat_list = []\n",
    "    for sublist in sentences:\n",
    "        for item in sublist:\n",
    "            flat_list.append(item)           \n",
    "    return flat_list\n",
    "\n",
    "def get_nouns(words):\n",
    "    nouns = []\n",
    "    porter = PorterStemmer()\n",
    "    for word, tag in words:\n",
    "        if tag.startswith('NN'):\n",
    "            if p.singular_noun(word):\n",
    "                nouns.append(p.singular_noun(word)) #plural nouns to singular nouns\n",
    "            else:\n",
    "                nouns.append(word)\n",
    "            #nouns.append(porter.stem(word)) #convert words to their basic form\n",
    "    return nouns\n",
    "\n",
    "def bow(sentence, corpus):\n",
    "    bag_vector = np.zeros(len(corpus))\n",
    "    for w in sentence:            \n",
    "        for i,word in enumerate(corpus):\n",
    "            if word == w:\n",
    "                bag_vector[i] += 1\n",
    "    return pd.Series(bag_vector)\n",
    "\n",
    "def get_used_noun_frequency(dic_1, dic_2, threshold_significance = 10):\n",
    "    significant_nouns = {}\n",
    "    for key, val in dic_1.items():\n",
    "        significant_nouns[key] = [val, 0]\n",
    "    \n",
    "    for key, val in dic_2.items():\n",
    "        if key in significant_nouns:\n",
    "            significant_nouns[key] = [significant_nouns[key][0], val]\n",
    "        else:\n",
    "            significant_nouns[key] = [0, val]\n",
    "            \n",
    "    for key, val in significant_nouns.copy().items():\n",
    "        if (val[0] < threshold_significance) and (val[1] < threshold_significance):\n",
    "            del significant_nouns[key]\n",
    "        \n",
    "    print(f\"number of significant nouns: {len(significant_nouns.keys())}\")\n",
    "    return significant_nouns\n",
    "\n",
    "def get_imbalanced_nouns(dic, coef = 2.2):\n",
    "    nouns_of_interest = []\n",
    "    \n",
    "    for key, val in dic.items():\n",
    "        if max(val[0], val[1]) - min(val[0], val[1]) * coef > 0:\n",
    "            nouns_of_interest.append(key)\n",
    "    print(f\"number of nouns of interest: {len(nouns_of_interest)}\")\n",
    "    return nouns_of_interest\n",
    "\n",
    "def get_nouns_and_their_synonims(nouns_of_interest, dic_all_nouns, threshold = 0.9):\n",
    "    dic_of_noun_differences = {}\n",
    "    \n",
    "    for noun in nouns_of_interest:\n",
    "\n",
    "            word_meanings = wn.synsets(noun, 'n')\n",
    "            for word_meaning in word_meanings:\n",
    "                for key, val in dic_all_nouns.items():\n",
    "                    if key != noun:\n",
    "\n",
    "                            word_meanings_target = wn.synsets(key, 'n')\n",
    "                            for word_meaning_target in word_meanings_target:\n",
    "                                if word_meaning.wup_similarity(word_meaning_target) > threshold:\n",
    "                                    if noun not in dic_of_noun_differences:\n",
    "                                        dic_of_noun_differences[noun] = set()\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "                                    else:\n",
    "                                        dic_of_noun_differences[noun].add(key)\n",
    "    return dic_of_noun_differences\n",
    "\n",
    "def nouns_synonyms_set_of_significance(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        #key = word, val = set of synonyms\n",
    "        for noun in val.copy():\n",
    "            if (dic_noun_frequency[key][0] >= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] >= dic_noun_frequency[noun][1]) or (dic_noun_frequency[key][0] <= dic_noun_frequency[key][1] and dic_noun_frequency[noun][0] <= dic_noun_frequency[noun][1]):\n",
    "                val.remove(noun)\n",
    "    return dic_of_noun_differences\n",
    "\n",
    "def print_nouns_stats(dic_of_noun_differences, dic_noun_frequency):\n",
    "    for key, val in dic_of_noun_differences.items():\n",
    "        for noun in val:\n",
    "            print(f\"{key}: {dic_noun_frequency[key][0]} - {dic_noun_frequency[key][1]}, {noun}: {dic_noun_frequency[noun][0]} - {dic_noun_frequency[noun][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dict(freq_dict, thr):\n",
    "     return {x : freq_dict[x] for x in freq_dict.keys() if freq_dict[x] >= thr}\n",
    "\n",
    "def optimal_threshold(freq_dict, plot=False):\n",
    "    \n",
    "    opt_thr, n_words = 0, len(freq_dict)\n",
    "    \n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        fig.subplots_adjust(hspace=0.75, wspace=0.5)\n",
    "    \n",
    "    \n",
    "    for ix, thr in enumerate(range(2, 11)):\n",
    "        fil_frequency = filter_dict(freq_dict, thr)\n",
    "        \n",
    "        if (n_words - len(fil_frequency)) >= 50:\n",
    "            n_words = len(fil_frequency)\n",
    "            opt_thr = thr \n",
    "        else:\n",
    "            n_words = len(fil_frequency)\n",
    "        \n",
    "        if plot:\n",
    "            x = np.arange(len(fil_frequency))\n",
    "            y = np.array(list(fil_frequency.values()))  \n",
    "            ax = fig.add_subplot(5, 2, ix+1)\n",
    "            ax.plot(x, y)\n",
    "            ax.set_title('Threshold = '+ str(thr))\n",
    "            ax.set_ylabel('frequency')\n",
    "            ax.set_xlabel('# of words')\n",
    "    \n",
    "    if plot:\n",
    "        plt.show()\n",
    "    \n",
    "    return opt_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model(X_train, y_train):\n",
    "    pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "\n",
    "    param_grid = [\n",
    "        {'classifier' : [LogisticRegression()],\n",
    "         'classifier__penalty' : ['l1', 'l2'],\n",
    "        'classifier__C' : np.logspace(-4, 4, 20),\n",
    "        'classifier__solver' : ['liblinear']}\n",
    "    ]\n",
    "\n",
    "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, n_jobs=-1)\n",
    "\n",
    "    best_clf = clf.fit(X_train, y_train)\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_similarity(word_meanings_1, word_meanings_2, threshold):\n",
    "    for meaning_1 in word_meanings_1:\n",
    "        for meaning_2 in word_meanings_2:\n",
    "            sim = meaning_1.wup_similarity(meaning_2)\n",
    "            if sim > threshold:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noun_disparity(noun_1, noun_2, freq_dict_1, freq_dict_2, threshold):\n",
    "        \n",
    "    freq_1_1 = freq_dict_1[noun_1]/(freq_dict_1[noun_1] + freq_dict_2[noun_1])\n",
    "    freq_1_2 = freq_dict_2[noun_1]/(freq_dict_1[noun_1] + freq_dict_2[noun_1])\n",
    "    \n",
    "    freq_2_1 = freq_dict_1[noun_2]/(freq_dict_1[noun_2] + freq_dict_2[noun_2])\n",
    "    freq_2_2 = freq_dict_2[noun_2]/(freq_dict_1[noun_2] + freq_dict_2[noun_2])\n",
    "    \n",
    "    if ((freq_1_1 - freq_1_2) > threshold and (freq_2_2 - freq_2_1) > threshold) or ((freq_1_2 - freq_1_1) > threshold and (freq_2_1 - freq_2_2) > threshold):\n",
    "            return True\n",
    "    return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_pairs(freq_dict_1, freq_dict_2):\n",
    "    pairs = []\n",
    "\n",
    "    for noun_1 in freq_dict_1.keys():\n",
    "        word_meanings_1 = wn.synsets(noun_1, 'n')\n",
    "        for noun_2 in freq_dict_2.keys():\n",
    "            if noun_1 != noun_2:\n",
    "                word_meanings_2 = wn.synsets(noun_2, 'n')\n",
    "                if threshold_similarity(word_meanings_1, word_meanings_2, 0.95) and noun_disparity(noun_1, noun_2, fil_frequency_nouns_1, fil_frequency_nouns_2, 0.10):\n",
    "                    if (noun_1, noun_2) not in pairs and (noun_2, noun_1) not in pairs:\n",
    "                        pairs.append((noun_1, noun_2))\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy LR abortion - Common Words: 0.59\n",
      "Training Accuracy LR abortion - Similar Words: 0.58\n",
      "Training Accuracy LR gay_marriage - Common Words: 0.66\n",
      "Training Accuracy LR gay_marriage - Similar Words: 0.64\n",
      "Training Accuracy LR darwin_theory_of_evolution - Common Words: 0.57\n",
      "Training Accuracy LR darwin_theory_of_evolution - Similar Words: 0.64\n"
     ]
    }
   ],
   "source": [
    "topics = { \"abortion\": [\"abortion_pro_choice.csv\", \"abortion_pro_life.csv\"], \n",
    "           \"gay_marriage\":[\"gay_marriage_for.csv\", \"gay_marriage_against.csv\"],\n",
    "           \"darwin_theory_of_evolution\" :[\"darwin_theory_of_evolution_for.csv\", \"darwin_theory_of_evolution_against.csv\"],\n",
    "         }\n",
    "\n",
    "for key, pair in topics.items():\n",
    "\n",
    "    df_1 = pd.read_csv(f\"./dataset_processed/{pair[0]}\", converters={2:ast.literal_eval})\n",
    "    df_2 = pd.read_csv(f\"./dataset_processed/{pair[1]}\", converters={2:ast.literal_eval})\n",
    "\n",
    "    tr_1 = df_1.sample(frac=0.8, random_state= 34)\n",
    "    tr_2 = df_2.sample(frac=0.8, random_state= 34)\n",
    "\n",
    "    words_1 = get_words(tr_1)\n",
    "    words_2 = get_words(tr_2)\n",
    "\n",
    "    tags_1 = nltk.pos_tag(words_1)\n",
    "    tags_2 = nltk.pos_tag(words_2)\n",
    "\n",
    "    nouns_1 = get_nouns(tags_1)\n",
    "    nouns_2 = get_nouns(tags_2)\n",
    "\n",
    "    frequency_nouns_1 = dict(Counter(nouns_1).most_common())\n",
    "    frequency_nouns_2 = dict(Counter(nouns_2).most_common()) \n",
    "\n",
    "    common_1 = list(frequency_nouns_1.keys())[:20]\n",
    "    common_2 = list(frequency_nouns_1.keys())[:20]\n",
    "\n",
    "    common = list(set([w for w in common_1] + [w for w in common_2]))\n",
    "\n",
    "    tr_1['bow_tokens_common'] = tr_1.apply(lambda t: bow(t.text, common), axis=1).values.tolist()\n",
    "    tr_1[common] = pd.DataFrame(tr_1.bow_tokens_common.values.tolist(), index= tr_1.index)\n",
    "\n",
    "    tr_2['bow_tokens_common'] = tr_2.apply(lambda t: bow(t.text, common), axis=1).values.tolist()\n",
    "    tr_2[common] = pd.DataFrame(tr_2.bow_tokens_common.values.tolist(), index= tr_2.index)\n",
    "\n",
    "    X_train_1 = np.append(tr_1[common], tr_2[common], axis = 0)\n",
    "    y_train_1 = np.append(np.zeros(len(tr_1)), np.ones(len(tr_2)))\n",
    "    \n",
    "    model_1 = lr_model(X_train_1, y_train_1)\n",
    "    print(f\"Training Accuracy LR {key} - Common Words: {model_1.score(X_train_1, y_train_1):.2f}\")\n",
    "    \n",
    "    thr_1 = optimal_threshold(frequency_nouns_1)\n",
    "    thr_2 = optimal_threshold(frequency_nouns_2)\n",
    "    thr = max(thr_1, thr_2)\n",
    "\n",
    "    fil_frequency_nouns_1 = filter_dict(frequency_nouns_1, thr)\n",
    "    fil_frequency_nouns_2 = filter_dict(frequency_nouns_2, thr)\n",
    "    \n",
    "    for word in fil_frequency_nouns_1.keys():\n",
    "        if word not in fil_frequency_nouns_2:\n",
    "            fil_frequency_nouns_2[word] = 0\n",
    "        \n",
    "    for word in fil_frequency_nouns_2.keys():\n",
    "        if word not in fil_frequency_nouns_1:\n",
    "            fil_frequency_nouns_1[word] = 0\n",
    "            \n",
    "    pairs = get_similar_pairs(fil_frequency_nouns_1, fil_frequency_nouns_2)\n",
    "    sim_words = list(set([ f1 for f1,f2 in pairs] + [ f2 for f1,f2 in pairs]))\n",
    "    \n",
    "    tr_1['bow_tokens_sim'] = tr_1.apply(lambda t: bow(t.text, sim_words), axis=1).values.tolist()\n",
    "    tr_1[sim_words] = pd.DataFrame(tr_1.bow_tokens_sim.values.tolist(), index= tr_1.index)\n",
    "\n",
    "    tr_2['bow_tokens_sim'] = tr_2.apply(lambda t: bow(t.text, sim_words), axis=1).values.tolist()\n",
    "    tr_2[sim_words] = pd.DataFrame(tr_2.bow_tokens_sim.values.tolist(), index= tr_2.index)\n",
    "    \n",
    "    X_train_2 = np.append(tr_1[sim_words], tr_2[sim_words], axis = 0)\n",
    "    y_train_2 = np.append(np.zeros(len(tr_1)), np.ones(len(tr_2)))\n",
    "    \n",
    "    model_2 = lr_model(X_train_2, y_train_2)\n",
    "    print(f\"Training Accuracy LR {key} - Similar Words: {model_2.score(X_train_2, y_train_2):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
